apiVersion: v1
kind: Namespace
metadata:
  name: cilium
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: cilium
  namespace: cilium
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: cilium
rules:
- apiGroups:
  - networking.k8s.io
  resources:
  - networkpolicies
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - discovery.k8s.io
  resources:
  - endpointslices
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - namespaces
  - services
  - nodes
  - endpoints
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - pods
  - nodes
  verbs:
  - get
  - list
  - watch
  - update
- apiGroups:
  - apiextensions.k8s.io
  resources:
  - customresourcedefinitions
  verbs:
  - create
  - get
  - list
  - update
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: cilium
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cilium
subjects:
- kind: ServiceAccount
  name: cilium
  namespace: cilium
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: cilium
  namespace: cilium
  labels:
    k8s-app: cilium
spec:
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
  selector:
    matchLabels:
      k8s-app: cilium
  template:
    metadata:
      annotations:
        # This annotation plus the CriticalAddonsOnly toleration makes
        # cilium to be a critical pod in the cluster, which ensures cilium
        # gets priority scheduling.
        # https://kubernetes.io/docs/tasks/administer-cluster/guaranteed-scheduling-critical-addon-pods/
        scheduler.alpha.kubernetes.io/critical-pod: ""
      labels:
        k8s-app: cilium
    spec:
      # In HA mode, cilium-agent pods must be able to run on all nodes as they
      # mount node's filesystem.
      hostNetwork: true
      serviceAccountName: cilium
      # In HA mode, remove the constraint that limits Cilium to only run on
      # master nodes. Cilium will be a DaemonSet, so it will run on all nodes.
      # If you want to run Cilium on master nodes, remove the tolerations key.
      tolerations:
      - operator: Exists
      initContainers:
      - name: mount-cgroup
        image: docker.io/cilium/cilium:{{ cilium_version }}
        command:
        - sh
        - -ec
        - |
          cp /usr/bin/cilium-mount /hostbin/cilium-mount;
          nsenter --mount=/proc/1/ns/mnt -- /bin/bash <<'EOF'
          /bin/mount | grep "cgroup on /sys/fs/cgroup" || {
            mkdir -p /sys/fs/cgroup
            mount -t cgroup2 none /sys/fs/cgroup || true
          }
          EOF
        volumeMounts:
        - name: cgroup-path
          mountPath: /sys/fs/cgroup
        - name: bpf-maps
          mountPath: /sys/fs/bpf
        - name: cilium-cgroup
          mountPath: /var/run/cilium/cgroupv2
        - name: hostbin
          mountPath: /hostbin
      - name: apply-sysctl-overwrites
        image: docker.io/cilium/cilium:{{ cilium_version }}
        command:
        - sh
        - -ec
        - |
          nsenter --mount=/proc/1/ns/mnt -- /bin/bash <<'EOF'
          sysctl -w net.core.bpf_jit_enable=1
          sysctl -w net.ipv4.ip_forward=1
          sysctl -w net.ipv6.conf.all.forwarding=1
          EOF
        securityContext:
          privileged: true
      - name: clean-cilium-state
        image: docker.io/cilium/cilium:{{ cilium_version }}
        command:
        - /init-container.sh
        env:
        - name: CILIUM_ALL_STATE
          value: "true"
        - name: CILIUM_BPF_STATE
          value: "true"
        volumeMounts:
        - name: bpf-maps
          mountPath: /sys/fs/bpf
        - name: cilium-cgroup
          mountPath: /var/run/cilium/cgroupv2
        securityContext:
          privileged: true
      containers:
      - name: cilium-agent
        image: docker.io/cilium/cilium:{{ cilium_version }}
        imagePullPolicy: IfNotPresent
        command:
        - cilium-agent
        args:
        - --config-dir=/tmp/cilium/config-map
        lifecycle:
          preStop:
            exec:
              command:
              - /cni-uninstall.sh
        env:
        - name: K8S_NODE_NAME
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: spec.nodeName
        - name: CILIUM_K8S_NAMESPACE
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.namespace
        - name: CILIUM_CLUSTERMESH_CONFIG
          value: /var/lib/cilium/clustermesh/
        - name: CILIUM_CNI_CHAINING_MODE
          value: "none"
        - name: CILIUM_CUSTOM_CNI_CONF
          value: "false"
        volumeMounts:
        - name: bpf-maps
          mountPath: /sys/fs/bpf
          readOnly: false
        - name: cilium-cgroup
          mountPath: /var/run/cilium/cgroupv2
        - name: cilium-run
          mountPath: /var/run/cilium
        - name: cgroup-path
          mountPath: /sys/fs/cgroup
          readOnly: true
        - name: etcd-certs
          mountPath: /var/lib/cilium/etcd-secrets
          readOnly: true
        - name: clustermesh-secrets
          mountPath: /var/lib/cilium/clustermesh
          readOnly: true
        - name: tmp
          mountPath: /tmp
        livenessProbe:
          httpGet:
            host: "127.0.0.1"
            path: /v1/healthz
            port: 9879
            scheme: HTTP
          initialDelaySeconds: 30
          periodSeconds: 30
          timeoutSeconds: 5
          failureThreshold: 10
          successThreshold: 1
        readinessProbe:
          httpGet:
            host: "127.0.0.1"
            path: /v1/status
            port: 9879
            scheme: HTTP
          initialDelaySeconds: 1
          periodSeconds: 10
          timeoutSeconds: 3
          failureThreshold: 3
          successThreshold: 1
        securityContext:
          capabilities:
            add:
            - CHOWN
            - KILL
            - NET_ADMIN
            - NET_RAW
            - IPC_LOCK
            - SYS_ADMIN
            - SYS_RESOURCE
            - DAC_OVERRIDE
            - FOWNER
            - SETGID
            - SETUID
          privileged: false
        resources:
          requests:
            cpu: 100m
            memory: 512Mi
          limits:
            cpu: "4"
            memory: 4Gi
      hostNetwork: true
      dnsPolicy: ClusterFirstWithHostNet
      volumes:
        # To keep state between restarts / upgrades
      - name: bpf-maps
        hostPath:
          path: /sys/fs/bpf
          type: DirectoryOrCreate
      - name: cilium-cgroup
        hostPath:
          path: /run/cilium/cgroupv2
          type: DirectoryOrCreate
      - name: cilium-run
        hostPath:
          path: /var/run/cilium
          type: DirectoryOrCreate
      # To keep state between restarts / upgrades
      - name: cgroup-path
        hostPath:
          path: /sys/fs/cgroup
          type: DirectoryOrCreate
      - name: etcd-certs
        secret:
          secretName: cilium-etcd-secrets
          optional: true
      - name: clustermesh-secrets
        secret:
          secretName: cilium-clustermesh
          optional: true
      - name: tmp
        emptyDir: {}
      - name: hostbin
        hostPath:
          path: /opt/cni/bin
          type: DirectoryOrCreate
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: cilium-config
  namespace: cilium
data:
  # Identity allocation mode selects how identities are shared between cilium
  # nodes. Possible values are "crd" or "kvstore".
  identity-allocation-mode: crd

  # If you want to run cilium in debug mode change this value to true
  debug: "false"

  # The agent can be put into the following three policy enforcement modes
  # default, always and never.
  enable-policy: "default"

  # Enable IPv4 connectivity between endpoints
  enable-ipv4: "true"

  # Enable IPv6 connectivity between endpoints
  enable-ipv6: "false"

  # If you want cilium monitor to aggregate tracing for packets, set this level
  # to "low", "medium", or "maximum". The higher the level, the less packets
  # that will be seen in monitor output.
  monitor-aggregation: "medium"

  # The monitor aggregation interval governs the typical time between monitor
  # notification events for each allowed connection.
  monitor-aggregation-interval: "5s"

  # The monitor aggregation flags determine which TCP flags which will trigger
  # monitor events for connections.
  monitor-aggregation-flags: "syn"

  # Specifies the ratio (0.0-1.0) of total system memory to use for dynamic
  # sizing of the TCP, UDP, and ICMP connection tables.
  bpf-map-dynamic-size-ratio: "0.0025"

  # Pre-allocation of map entries allows per-packet latency to be reduced, at
  # the expense of up-front memory allocation for the entries in the maps. The
  # default value below will minimize memory usage in the default installation;
  # users who are sensitive to latency may consider setting this to "true".
  #
  # This option was introduced in Cilium 1.4. Cilium 1.3 and earlier ignore
  # this option and behave as though it is set to "true".
  #
  # If this value is modified, then during the next Cilium startup the restore
  # of existing endpoints and connections may be disrupted. This may lead to
  # policy drops or interruptions to ongoing connections for a brief period
  # until the BPF maps are repopulated.
  preallocate-bpf-maps: "false"

  # Regular expression matching compatible Istio sidecar istio-proxy
  # container image names
  sidecar-istio-proxy-image: "cilium/istio_proxy"

  # Encapsulation mode for communication between nodes
  # Possible values:
  #   - disabled
  #   - vxlan (default)
  #   - geneve
  encapsulation: "vxlan"

  # Cluster name
  cluster-name: "{{ cluster_name }}"

  # Enables L7 proxy for L7 policy enforcement and visibility
  enable-l7-proxy: "true"

  # wait for kube-proxy to be removed
  wait-bpf-mount: "true"

  # Enable well-known identities
  enable-well-known-identities: "false"

  # Enable remote node identity
  enable-remote-node-identity: "true"

  # Enable bandwidth manager
  enable-bandwidth-manager: "false"

  # Enable BBR TCP congestion control for the Pods
  enable-bbr: "false"

  # Enable hubble
  enable-hubble: "false"

  # Enable local redirect policy
  enable-local-redirect-policy: "false"

  # Enable SRv6 encapsulation
  enable-srv6: "false"

  # Enable IPv4 masquerading
  enable-ipv4-masquerade: "true"

  # Enable IPv6 masquerading
  enable-ipv6-masquerade: "true"

  # Enable BPF-based masquerading
  enable-bpf-masquerade: "true"

  # Enable endpoint health checking
  enable-endpoint-health-checking: "true"

  # Enable health checking between nodes
  enable-health-checking: "true"

  # Enable health checking nodeport
  enable-health-check-nodeport: "true"

  # Enable ICMPv6 DAD
  enable-icmp-rule6: "true"

  # Enable IPv4 fragmentation tracking
  enable-ipv4-fragment-tracking: "true"

  # Enable IPv6 fragmentation tracking
  enable-ipv6-fragment-tracking: "true"

  # Enable session affinity
  enable-session-affinity: "true"

  # Enable NodePort
  enable-nodeport: "true"

  # Enable Kubernetes EndpointSlice feature
  enable-k8s-endpoint-slice: "true"

  # Enable auto-direct-node-routes
  auto-direct-node-routes: "false"

  # Enable kube-proxy replacement
  kube-proxy-replacement: "false"

  # Enable kube-proxy replacement partial mode
  kube-proxy-replacement-healthz-bind-address: ""

  # Enable Cilium to run in the host networking namespace
  enable-host-reachable-services: "false"

  # Enable Cilium to run in the host networking namespace for TCP
  enable-host-reachable-services-tcp: "false"

  # Enable Cilium to run in the host networking namespace for UDP
  enable-host-reachable-services-udp: "false"

  # Enable Cilium to run in the host networking namespace for protocols other than TCP/UDP
  enable-host-reachable-services-protos: "false"

  # Enable BPF-based socket-level LB for hostns
  enable-socket-lb: "false"

  # Enable BPF-based socket-level LB for peers
  enable-socket-lb-peer: "false"

  # Enable BPF-based host routing
  enable-bpf-host-routing: "false"

  # Enable BPF-based TPROXY
  enable-bpf-tproxy: "false"

  # Enable BPF-based external cluster IP
  enable-bpf-external-clusterip: "false"

  # Enable BPF-based masquerading for IPv4 traffic leaving the node from
  # endpoints
  enable-bpf-masquerade: "true"

  # Enable BPF-based masquerading for IPv6 traffic leaving the node from
  # endpoints
  enable-bpf-masquerade-ipv6: "false"

  # Enable BPF clock source for BPF-based NAT
  enable-bpf-clock-proxy: "false"

  # Enable BPF-based NAT46/64 handling
  enable-bpf-nat46x64: "false"

  # Enable BPF-based IPv4 masquerading for IPv6 traffic
  enable-ipv6-masquerade: "true"

  # Enable BPF-based IPv6 masquerading for IPv4 traffic
  enable-ipv4-masquerade: "true"

  # Enable BPF-based masquerading for IPv4 traffic leaving the node from
  # endpoints
  enable-bpf-masquerade: "true"

  # Enable BPF-based masquerading for IPv6 traffic leaving the node from
  # endpoints
  enable-bpf-masquerade-ipv6: "false"

  # Enable BPF clock source for BPF-based NAT
  enable-bpf-clock-proxy: "false"

  # Enable BPF-based NAT46/64 handling
  enable-bpf-nat46x64: "false"

  # Enable BPF-based IPv4 masquerading for IPv6 traffic
  enable-ipv6-masquerade: "true"

  # Enable BPF-based IPv6 masquerading for IPv4 traffic
  enable-ipv4-masquerade: "true"

  # IPv4 CIDR range to allocate pod IPs from
  ipv4-range: "{{ pod_cidr }}"

  # IPv6 CIDR range to allocate pod IPs from
  ipv6-range: ""

  # Enable IPv4 native routing CIDR
  ipv4-native-routing-cidr: "{{ pod_cidr }}"

  # Enable IPv6 native routing CIDR
  ipv6-native-routing-cidr: ""

  # Enable IPv4 pod CIDR
  enable-ipv4: "true"

  # Enable IPv6 pod CIDR
  enable-ipv6: "false"

